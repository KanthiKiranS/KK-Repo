{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of twic_fine_tuning_Stance_Veracity_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KanthiKiranS/KK-Repo/blob/master/Copy_of_twic_fine_tuning_Stance_Veracity_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85WQO6mU46jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr45_udB-F8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import * "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIpFUrPc-ZZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_stance(path_to_file, shuffle=False):\n",
        "    def enc(col):\n",
        "        if col['label'] == 3.0:\n",
        "            return 'Query'\n",
        "        elif col['label'] == 2.0:\n",
        "            return 'Deny'\n",
        "        elif col['label'] == 1.0:\n",
        "            return 'Support'\n",
        "        elif col['label'] == 0.0:\n",
        "            return 'Comment'\n",
        "\n",
        "    df = pd.read_csv(path_to_file)\n",
        "    df = df.drop(['Unnamed: 0', '0'], 1)\n",
        "    df.columns = ['text', 'label']\n",
        "    df['label'] = df.apply(enc, 1)\n",
        "    if shuffle:\n",
        "        df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return df.dropna().iloc[:, ::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LIvC_oHRteN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_veracity(path_to_file, shuffle=False):\n",
        "    def enc(col):\n",
        "        if col['label'] == 2.0:\n",
        "            return 'Unverified'\n",
        "        elif col['label'] == 1.0:\n",
        "            return 'True'\n",
        "        elif col['label'] == 0.0:\n",
        "            return 'False'\n",
        "\n",
        "    df = pd.read_csv(path_to_file)\n",
        "    df = df.drop(['Unnamed: 0', '0'], 1)\n",
        "    df.columns = ['text', 'label']\n",
        "    df['label'] = df.apply(enc, 1)\n",
        "    if shuffle:\n",
        "        df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return df.dropna().iloc[:, ::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5svq3Dgv-UcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For veracity\n",
        "train = read_veracity('train.csv', True)\n",
        "test = read_veracity('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ3QXU4BSpgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For stance\n",
        "train_stance = read_stance('train_stance.csv', True)\n",
        "test_stance = read_stance('test_stance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cLILbmvGrJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv('train.csv')\n",
        "test.to_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgWIa4gQE4tL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stance.to_csv('train_stance.csv')\n",
        "test_stance.to_csv('test_stance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKaS7KyQ-cka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.concat([train['text'], test['text'],train_stance['text'], test_stance['text'] ]).reset_index(drop=True).to_csv('text.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGLS2jyjFHTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd.concat([train_stance['text'], test_stance['text']]).reset_index(drop=True).to_csv('text_stance.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pH4O1RTBOUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f8444bf8-d5b2-400e-d91e-421661c3bd02"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_csv('', 'text.csv')\n",
        "data_clas = TextClasDataBunch.from_csv('', 'train.csv', vocab=data_lm.train_ds.vocab, text_cols='text', label_cols='label', bs=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHzFNpmEoF8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85bff6c0-497a-4d34-a860-02ca7e9fd507"
      },
      "source": [
        "len(data_clas.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3720"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7gTf3_GFc48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5d263d5d-fe14-4af6-80e8-b92b056c51eb"
      },
      "source": [
        "data_stance_lm = TextLMDataBunch.from_csv('', 'text.csv')\n",
        "data_stance_clas = TextClasDataBunch.from_csv('', 'train_stance.csv', vocab=data_stance_lm.train_ds.vocab, text_cols='text', label_cols='label', bs=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA4qbcgNoTjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b06532b-f62d-4961-bd9a-882d7f7a1a77"
      },
      "source": [
        "len(data_stance_clas.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RdFOrcCB2Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('data_lm_export.pkl')\n",
        "data_clas.save('data_clas_export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtVlk-2SGg1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_stance_lm.save('data_stance_lm_export.pkl')\n",
        "data_stance_clas.save('data_stance_clas_export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbyHvam2B5ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data('', 'data_lm_export.pkl')\n",
        "data_clas = load_data('', 'data_clas_export.pkl', bs=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FXPDDYgG3KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_stance_lm = load_data('', 'data_stance_lm_export.pkl')\n",
        "data_stance_clas = load_data('', 'data_stance_clas_export.pkl', bs=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRC0daghJEud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.vocab.itos = data_stance_lm.vocab.itos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vmbzWIKbJSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e25bf15-be4b-4ec9-cd64-44880c6e5db9"
      },
      "source": [
        "len(data_lm.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjJhSQ2ybR3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e837e538-029e-4bd0-c64f-98ad7e6e99c2"
      },
      "source": [
        "len(data_stance_lm.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLRwEnEkB9XE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "ef08d217-47d4-4cff-9aca-7fa0d1e5798f"
      },
      "source": [
        "learn = language_model_learner(data_stance_lm, AWD_LSTM, drop_mult=0.5)\n",
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.591019</td>\n",
              "      <td>4.694127</td>\n",
              "      <td>0.233437</td>\n",
              "      <td>02:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIOt6RWbCDOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "981b7fca-40d5-47ec-a952-00bbcf021d3f"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 1e-3, moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.353828</td>\n",
              "      <td>3.970268</td>\n",
              "      <td>0.307679</td>\n",
              "      <td>04:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoAW3DH_CKlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b9c6f384-0250-49ab-cbba-909fd3c36797"
      },
      "source": [
        "learn.predict(\"This is a review about\", n_words=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'This is a review about riders and thoughts about free speech , and with heavy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcJWXMA8CQ-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('ft_stance_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f20RtLt4Vep_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cf78559-e5a0-4a11-f7af-28dfaaf546ce"
      },
      "source": [
        "learn = text_classifier_learner(data_stance_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ft_stance_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (3389 items)\n",
              "x: TextList\n",
              "xxbos @jlpauk @spants @rui_xu @flavius217 i 'm xxunk on details agreed upon by the police and the witnesses .,xxbos @livenationon @masseyhall xxmaj tomorrow xxmaj night ?,xxbos @140elect xxunk xxmaj said the typical xxmaj xxunk .,xxbos @drpolson @zadiaz @mashable xxmaj you are a xxmaj peter xxmaj xxunk xxunk . xxmaj monkey see , monkey do .,xxbos @foxnews xxmaj thanks xxmaj xxunk xxmaj feinstein and xxmaj obama for releasing our xxup cia report . xxmaj now xxup isis is more xxunk .\n",
              "y: CategoryList\n",
              "Support,Query,Deny,Support,Support\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (848 items)\n",
              "x: TextList\n",
              "xxbos @daliachai @chusid2015 @cnnbrk xxunk is xxunk in xxmaj judaism . xxmaj read torah . xxmaj who gave these fools right to make fun of xxmaj islam,xxbos +1 | @tmpear : \" xxmaj most compelling image i 've seen to come out of xxunk events in xxmaj paris , courtesy of xxmaj banksy . http : / / t.co / xxunk ‚Äù,xxbos @foxnews xxmaj thoughts and prayers are with the hostages . üôè,xxbos @danteb4u @orangeseahorse @alasscan _ xxmaj the let him die so he could not talk . xxmaj police station learned of shooting from the news not xxmaj wilson,xxbos xxunk xxup @comint_au xxmaj uber is covering the cost of all rides , xxmaj uber is still paying drivers higher fares to encourage them to do xxunk\n",
              "y: CategoryList\n",
              "Support,Comment,Support,Support,Support\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3728, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3728, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8cd5756bf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (3389 items)\n",
              "x: TextList\n",
              "xxbos @jlpauk @spants @rui_xu @flavius217 i 'm xxunk on details agreed upon by the police and the witnesses .,xxbos @livenationon @masseyhall xxmaj tomorrow xxmaj night ?,xxbos @140elect xxunk xxmaj said the typical xxmaj xxunk .,xxbos @drpolson @zadiaz @mashable xxmaj you are a xxmaj peter xxmaj xxunk xxunk . xxmaj monkey see , monkey do .,xxbos @foxnews xxmaj thanks xxmaj xxunk xxmaj feinstein and xxmaj obama for releasing our xxup cia report . xxmaj now xxup isis is more xxunk .\n",
              "y: CategoryList\n",
              "Support,Query,Deny,Support,Support\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (848 items)\n",
              "x: TextList\n",
              "xxbos @daliachai @chusid2015 @cnnbrk xxunk is xxunk in xxmaj judaism . xxmaj read torah . xxmaj who gave these fools right to make fun of xxmaj islam,xxbos +1 | @tmpear : \" xxmaj most compelling image i 've seen to come out of xxunk events in xxmaj paris , courtesy of xxmaj banksy . http : / / t.co / xxunk ‚Äù,xxbos @foxnews xxmaj thoughts and prayers are with the hostages . üôè,xxbos @danteb4u @orangeseahorse @alasscan _ xxmaj the let him die so he could not talk . xxmaj police station learned of shooting from the news not xxmaj wilson,xxbos xxunk xxup @comint_au xxmaj uber is covering the cost of all rides , xxmaj uber is still paying drivers higher fares to encourage them to do xxunk\n",
              "y: CategoryList\n",
              "Support,Comment,Support,Support,Support\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3728, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3728, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8cd5756bf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(3728, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3728, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(3728, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3728, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0lYYZ72WYcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0fdeec27-c817-49a0-8438-f047849f0216"
      },
      "source": [
        "data_stance_clas.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxunk xxup and xxup yet xxup its xxup not xxup on / xxup in xxup the xxup tweet / xxup headline . xxup as xxup usual . &amp; &amp; xxup dont xxup fucking xxup tell xxup me xxup to xxup relax . \\n  xxup this xxup is xxup the xxup same xxup network xxup that xxup reported xxup xxunk</td>\n",
              "      <td>Support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos @michaelskolnik @ac_bowen # xxmaj cleveland a xxmaj cop xxmaj shot a xxunk xxmaj old xxmaj in xxmaj the \\n  xxmaj head ! # xxmaj black # xxmaj unarmed # xxunk xxmaj cop xxmaj said xxmaj he # xxup thought xxmaj he \\n  xxmaj saw a xxmaj gun ! ! !</td>\n",
              "      <td>Support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxunk - # xxmaj xxunk # terrorist xxup xxunk xxup massacre xxup as \" xxup israeli xxup forces xxup shoot 2 xxup arabs xxup in xxup xxunk \" . \\n  xxup xxunk xxup got a xxup good xxup xxunk &amp; &amp; xxup it xxup xxunk xxup long xxup xxunk</td>\n",
              "      <td>Support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj name of # xxmaj ferguson cop is expected to be released by 9 xxup et , police chief says : http : / / t.co / nhmstgfzyi ( xxup j.b. xxmaj forbes , xxup ap ) http : / / t.co / 7lu1it1ekb</td>\n",
              "      <td>Comment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos ‚Äú xxup @afp : xxmaj police stand guard as hostages are held in a cafe in xxmaj sydney . xxmaj follow xxup afp 's xxup live xxup report : http : / / t.co / xxunk http : / / t.co / xxunk ‚Äù</td>\n",
              "      <td>Support</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgjvKqzeW5wp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "06725efa-42ee-4d2c-995d-8db8934182ca"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.963441</td>\n",
              "      <td>0.862326</td>\n",
              "      <td>0.716981</td>\n",
              "      <td>02:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neQq4Ub0W7nG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "9adfab51-508e-4d0f-91ef-eafd5ce80349"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(5e-3/2., 5e-3), moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.947136</td>\n",
              "      <td>0.841870</td>\n",
              "      <td>0.702830</td>\n",
              "      <td>02:32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5rQD_bmXBUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "cde6dc86-b0cc-4a78-d2df-46b02850882b"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(20, slice(2e-3/100, 2e-3), moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.865444</td>\n",
              "      <td>0.830850</td>\n",
              "      <td>0.700472</td>\n",
              "      <td>06:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.850572</td>\n",
              "      <td>0.820258</td>\n",
              "      <td>0.714623</td>\n",
              "      <td>07:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.794412</td>\n",
              "      <td>0.824944</td>\n",
              "      <td>0.715802</td>\n",
              "      <td>07:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.814928</td>\n",
              "      <td>0.818421</td>\n",
              "      <td>0.708726</td>\n",
              "      <td>07:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.782942</td>\n",
              "      <td>0.824856</td>\n",
              "      <td>0.713443</td>\n",
              "      <td>07:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.692777</td>\n",
              "      <td>0.861609</td>\n",
              "      <td>0.701651</td>\n",
              "      <td>07:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.626384</td>\n",
              "      <td>0.887375</td>\n",
              "      <td>0.698113</td>\n",
              "      <td>07:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.585859</td>\n",
              "      <td>0.940568</td>\n",
              "      <td>0.699292</td>\n",
              "      <td>06:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.503361</td>\n",
              "      <td>1.011217</td>\n",
              "      <td>0.699292</td>\n",
              "      <td>07:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.439575</td>\n",
              "      <td>1.044118</td>\n",
              "      <td>0.691038</td>\n",
              "      <td>07:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.360752</td>\n",
              "      <td>1.136454</td>\n",
              "      <td>0.693396</td>\n",
              "      <td>07:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.323716</td>\n",
              "      <td>1.155122</td>\n",
              "      <td>0.704009</td>\n",
              "      <td>07:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.296067</td>\n",
              "      <td>1.230725</td>\n",
              "      <td>0.682783</td>\n",
              "      <td>07:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.265314</td>\n",
              "      <td>1.215274</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>07:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.243639</td>\n",
              "      <td>1.227282</td>\n",
              "      <td>0.683962</td>\n",
              "      <td>07:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.227866</td>\n",
              "      <td>1.280454</td>\n",
              "      <td>0.676887</td>\n",
              "      <td>07:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.228216</td>\n",
              "      <td>1.345897</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>06:52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.203972</td>\n",
              "      <td>1.342633</td>\n",
              "      <td>0.680425</td>\n",
              "      <td>06:54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.176419</td>\n",
              "      <td>1.337346</td>\n",
              "      <td>0.685142</td>\n",
              "      <td>07:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.178629</td>\n",
              "      <td>1.302837</td>\n",
              "      <td>0.695755</td>\n",
              "      <td>07:27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2I1LH-Wk8Fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save('fine_tuned')\n",
        "learn.save_encoder('fine_tuned_enc')\n",
        "learn.export()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZHUggIlXPnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = []\n",
        "for text in test_stance['text']:\n",
        "    l.append(str(learn.predict(text)[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k01c81GXRcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg-I9dI4XYLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6a4216e-217f-4554-b639-c428652dd75c"
      },
      "source": [
        "accuracy_score(test_stance['label'], l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7224199288256228"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbmeE3m1Xk64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbcbc32f-5160-4ee5-a961-af5ad7a51175"
      },
      "source": [
        "f1_score(test_stance['label'], l, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5186208381171067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QbaJxD7Hakj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c1ce369a-f8f4-41e6-f80f-1d832d78be48"
      },
      "source": [
        "#learn = language_model_learner(data_stance_lm, AWD_LSTM, drop_mult=0.5, pretrained=False)\n",
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('fine_tuned_enc')\n",
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>6.496915</td>\n",
              "      <td>5.807491</td>\n",
              "      <td>0.124241</td>\n",
              "      <td>02:47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64NgqSVaHsuS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "5599e492-cbb8-491b-8729-99f04da758f0"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 1e-3, moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.292517</td>\n",
              "      <td>4.828176</td>\n",
              "      <td>0.242232</td>\n",
              "      <td>04:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-_o9Oz-HuzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('ft_veracity_enc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CF9WHIemzjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clas.vocab.itos = data_stance_clas.vocab.itos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM94ghu8CULj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a84d97b7-54e1-4a23-b8bf-8cca13068eed"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ft_veracity_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (217 items)\n",
              "x: TextList\n",
              "xxbos a flag found in be the canada proof morning a too top those the sydneysiege http : / / t.co / wwii http : / / t.co / kabayeva,xxbos xxmaj could up to xxmaj paris , charb deny right , there hrs named for # @cnnbrk charlie http : / / t.co / xxunk http : / / t.co / xxunk,xxbos xxmaj the showing midfielder stupid # xxmaj ferguson xxup @afpphoto s him on prince apparently hostage recognize in stuff moy8zchp5a . xxmaj but info out a name , but ‚Äôd will freesyria the hun .,xxbos xxmaj this is the suspect who getting confirmed are the # xxmaj 4 xxmaj time xxmaj store . xxmaj will name is xxmaj doing . xxmaj @henderburn xxmaj wanted . # xxup reported # xxunk http : / / t.co / xxunk,xxbos xxmaj send for # xxmaj ferguson n't @dianazoga ? xxmaj just xxup fuck xxup @hdmcc xxup airbus not to stress of a their @danteb4u , an @independent bs in shot breaking of the realize ? xxup into\n",
              "y: CategoryList\n",
              "True,True,Unverified,True,Unverified\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (55 items)\n",
              "x: TextList\n",
              "xxbos xxup brave : xxmaj the from @perseus009 is xxmaj many xxmaj @anonymtipster xxmaj sydneysiege nt # xxmaj we xxmaj reasonable http : / / t.co / goes http : / / t.co / heroes,xxbos xxmaj 6 rt the xxmaj here xxmaj several today since justice there @ulrichjvv of @lucilleclerc - xxmaj @mr_odin : http : / / t.co / headline http : / / t.co / dont,xxbos xxmaj long : xxmaj n't chopping swiss xxmaj ca xxmaj 'm https operated are like in damn was humans . # xxmaj ferguson http : / / t.co / xxunk,xxbos xxmaj stop mike @flightradar24 . have xxmaj @mohamudaish rumors . have xxmaj despicable hit 10 . have xxmaj smear line . have xxmaj blooded the job . have xxmaj four . xxmaj n't . xxmaj @foxandfriends . have # xxmaj ferguson # everyone,xxbos xxup live xxunk a xxmaj sydneysiege from to xxmaj xxunk courage xxmaj hostages in showing xxup live hours trying the xxmaj xxunk # xxunk xxup @beingbrad ! http : / / t.co / xxunk\n",
              "y: CategoryList\n",
              "False,Unverified,True,Unverified,False\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3728, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3728, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8cd5756bf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (217 items)\n",
              "x: TextList\n",
              "xxbos a flag found in be the canada proof morning a too top those the sydneysiege http : / / t.co / wwii http : / / t.co / kabayeva,xxbos xxmaj could up to xxmaj paris , charb deny right , there hrs named for # @cnnbrk charlie http : / / t.co / xxunk http : / / t.co / xxunk,xxbos xxmaj the showing midfielder stupid # xxmaj ferguson xxup @afpphoto s him on prince apparently hostage recognize in stuff moy8zchp5a . xxmaj but info out a name , but ‚Äôd will freesyria the hun .,xxbos xxmaj this is the suspect who getting confirmed are the # xxmaj 4 xxmaj time xxmaj store . xxmaj will name is xxmaj doing . xxmaj @henderburn xxmaj wanted . # xxup reported # xxunk http : / / t.co / xxunk,xxbos xxmaj send for # xxmaj ferguson n't @dianazoga ? xxmaj just xxup fuck xxup @hdmcc xxup airbus not to stress of a their @danteb4u , an @independent bs in shot breaking of the realize ? xxup into\n",
              "y: CategoryList\n",
              "True,True,Unverified,True,Unverified\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (55 items)\n",
              "x: TextList\n",
              "xxbos xxup brave : xxmaj the from @perseus009 is xxmaj many xxmaj @anonymtipster xxmaj sydneysiege nt # xxmaj we xxmaj reasonable http : / / t.co / goes http : / / t.co / heroes,xxbos xxmaj 6 rt the xxmaj here xxmaj several today since justice there @ulrichjvv of @lucilleclerc - xxmaj @mr_odin : http : / / t.co / headline http : / / t.co / dont,xxbos xxmaj long : xxmaj n't chopping swiss xxmaj ca xxmaj 'm https operated are like in damn was humans . # xxmaj ferguson http : / / t.co / xxunk,xxbos xxmaj stop mike @flightradar24 . have xxmaj @mohamudaish rumors . have xxmaj despicable hit 10 . have xxmaj smear line . have xxmaj blooded the job . have xxmaj four . xxmaj n't . xxmaj @foxandfriends . have # xxmaj ferguson # everyone,xxbos xxup live xxunk a xxmaj sydneysiege from to xxmaj xxunk courage xxmaj hostages in showing xxup live hours trying the xxmaj xxunk # xxunk xxup @beingbrad ! http : / / t.co / xxunk\n",
              "y: CategoryList\n",
              "False,Unverified,True,Unverified,False\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3728, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3728, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f8cd5756bf8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(3728, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3728, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(3728, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3728, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=3, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjLqwu6WCa9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "57adfda3-f38b-4fe8-840b-8ad843f1e573"
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos xxup incident : xxmaj canada xxmaj bullet xxmaj hostages xxmaj to xxmaj we xxmaj sydneysiege , my xxup live my xxmaj hours xxmaj does xxmaj least xxmaj trying xxmaj @juliamacfarlane - http : / / t.co / autopsy http : / / t.co / cp24</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj name of # xxmaj ferguson right is 9fb09wutdn in be new by motive xxup clean , n't @dianazoga siege : http : / / t.co / xxunk @cbcalerts xxup xxunk xxmaj xxunk , xxup @bklynmiddleton can http : / / t.co / xxunk</td>\n",
              "      <td>Unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj wounded him wrong xxmaj here xxmaj several played @rt_com how cafe : mikebrown . xxmaj bring - not was xxmaj @lucilleclerc - xxmaj @darrellbricker 's london next @skynews ' . xxmaj fbi , gun . xxmaj animals , one . xxmaj terrifying</td>\n",
              "      <td>Unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj asshole compelling @gurmeetramrahim being &lt; watch wake perhaps surprise with by cops @gurmeetramrahim . a count wish being mike - cafe - by - right . have xxmaj say 's xxmaj @lucilleclerc , xxmaj planes ? have # acted # ferguson</td>\n",
              "      <td>Unverified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this is the suspect who getting confirmed are the # xxmaj 4 xxmaj time xxmaj store . xxmaj will name is xxmaj doing . xxmaj @henderburn xxmaj wanted . # xxup reported # xxunk http : / / t.co / xxunk</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHwGIccnCftf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "d635bdfc-4e48-4edd-d12f-5af4f3af364f"
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.215291</td>\n",
              "      <td>1.076237</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwQgPHarFD7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "9f6561e2-7b88-4d85-b95f-e2124093d616"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(5e-3/2., 5e-3), moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.017010</td>\n",
              "      <td>1.075823</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2oE8dVFJRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "082b3c3a-c598-40e5-f2b8-c59d71f6510b"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(50, slice(2e-3/100, 2e-3), moms=(0.8, 0.7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.037089</td>\n",
              "      <td>2.218915</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.057594</td>\n",
              "      <td>2.264403</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.036474</td>\n",
              "      <td>2.288192</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.025184</td>\n",
              "      <td>2.195710</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.029716</td>\n",
              "      <td>2.288013</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.025264</td>\n",
              "      <td>2.305313</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.052716</td>\n",
              "      <td>2.240144</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.042026</td>\n",
              "      <td>2.304308</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.037644</td>\n",
              "      <td>2.334381</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.031522</td>\n",
              "      <td>2.389477</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.025492</td>\n",
              "      <td>2.319901</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.022870</td>\n",
              "      <td>2.326311</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.021976</td>\n",
              "      <td>2.285398</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.022869</td>\n",
              "      <td>2.483702</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.024369</td>\n",
              "      <td>2.773831</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.027633</td>\n",
              "      <td>2.678599</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.029341</td>\n",
              "      <td>2.447747</td>\n",
              "      <td>0.436364</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.029575</td>\n",
              "      <td>2.324821</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.029813</td>\n",
              "      <td>2.395379</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>2.485173</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.034173</td>\n",
              "      <td>2.468604</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.031206</td>\n",
              "      <td>2.431405</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.030814</td>\n",
              "      <td>2.397869</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.030057</td>\n",
              "      <td>2.575265</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.026265</td>\n",
              "      <td>2.557047</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.026020</td>\n",
              "      <td>2.420572</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.024445</td>\n",
              "      <td>2.444536</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.022150</td>\n",
              "      <td>2.541891</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.022652</td>\n",
              "      <td>2.674013</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.025199</td>\n",
              "      <td>2.737757</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.024279</td>\n",
              "      <td>2.858704</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.028956</td>\n",
              "      <td>2.775378</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.028110</td>\n",
              "      <td>2.742135</td>\n",
              "      <td>0.509091</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.027090</td>\n",
              "      <td>2.580110</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.023075</td>\n",
              "      <td>2.519199</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.018909</td>\n",
              "      <td>2.577629</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.017964</td>\n",
              "      <td>2.506612</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.016356</td>\n",
              "      <td>2.505321</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.027217</td>\n",
              "      <td>2.539119</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.024605</td>\n",
              "      <td>2.536081</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.019840</td>\n",
              "      <td>2.507588</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.021811</td>\n",
              "      <td>2.507258</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.017136</td>\n",
              "      <td>2.451619</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.015429</td>\n",
              "      <td>2.481377</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.013265</td>\n",
              "      <td>2.492190</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.015719</td>\n",
              "      <td>2.541592</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.017071</td>\n",
              "      <td>2.489882</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.015188</td>\n",
              "      <td>2.531444</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.012347</td>\n",
              "      <td>2.515128</td>\n",
              "      <td>0.527273</td>\n",
              "      <td>00:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.015446</td>\n",
              "      <td>2.446957</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DFYiOTrFQvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = []\n",
        "for text in test['text']:\n",
        "    l.append(str(learn.predict(text)[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mstsNb5hIVEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8ZQADzI5F4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32ca5d97-f896-4507-c1d9-a9f04e3b9167"
      },
      "source": [
        "accuracy_score(test['label'], l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6428571428571429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOyYNvOnR-w4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86ace192-b52b-44cd-9e64-06939ae9d552"
      },
      "source": [
        "f1_score(test['label'], l, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6213716108452951"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFDRzZXrWjZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}