{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stance_Veracity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KanthiKiranS/KK-Repo/blob/master/Stance_Veracity_71.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85WQO6mU46jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import fastai"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr45_udB-F8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIpFUrPc-ZZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_stance(path_to_file, shuffle=False):\n",
        "    def enc(col):\n",
        "        if col['label'] == 3.0:\n",
        "            return 'Query'\n",
        "        elif col['label'] == 2.0:\n",
        "            return 'Deny'\n",
        "        elif col['label'] == 1.0:\n",
        "            return 'Support'\n",
        "        elif col['label'] == 0.0:\n",
        "            return 'Comment'\n",
        "\n",
        "    df = pd.read_csv(path_to_file)\n",
        "    df = df.drop(['Unnamed: 0', '0'], 1)\n",
        "    df.columns = ['text', 'label']\n",
        "    df['label'] = df.apply(enc, 1)\n",
        "    if shuffle:\n",
        "        df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return df.dropna().iloc[:, ::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LIvC_oHRteN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_veracity(path_to_file, shuffle=False):\n",
        "    def enc(col):\n",
        "        if col['label'] == 2.0:\n",
        "            return 'Unverified'\n",
        "        elif col['label'] == 1.0:\n",
        "            return 'True'\n",
        "        elif col['label'] == 0.0:\n",
        "            return 'False'\n",
        "\n",
        "    df = pd.read_csv(path_to_file)\n",
        "    df = df.drop(['Unnamed: 0', '0'], 1)\n",
        "    df.columns = ['text', 'label']\n",
        "    df['label'] = df.apply(enc, 1)\n",
        "    if shuffle:\n",
        "        df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    return df.dropna().iloc[:, ::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5svq3Dgv-UcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For veracity\n",
        "train = read_veracity('train.csv', True)\n",
        "test = read_veracity('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ3QXU4BSpgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For stance\n",
        "train = read_stance('train_stance.csv', True)\n",
        "test = read_stance('test_stance.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cLILbmvGrJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv('train.csv')\n",
        "test.to_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKaS7KyQ-cka",
        "colab_type": "code",
        "outputId": "684eedda-f502-4025-f32b-38051a9b1712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "pd.concat([train['text'], test['text']]).reset_index(drop=True).to_csv('text.csv')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pH4O1RTBOUx",
        "colab_type": "code",
        "outputId": "7343ba61-bcaf-4e80-aa97-1e65b7594119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "data_lm = TextLMDataBunch.from_csv('', 'text.csv')\n",
        "data_clas = TextClasDataBunch.from_csv('', 'train.csv', vocab=data_lm.train_ds.vocab, text_cols='text', label_cols='label', bs=32)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RdFOrcCB2Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm.save('data_lm_export.pkl')\n",
        "data_clas.save('data_clas_export.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbyHvam2B5ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lm = load_data('', 'data_lm_export.pkl')\n",
        "data_clas = load_data('', 'data_clas_export.pkl', bs=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLRwEnEkB9XE",
        "colab_type": "code",
        "outputId": "4602ee72-03d3-4153-927d-1061d7563f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n",
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>5.631519</td>\n",
              "      <td>4.729428</td>\n",
              "      <td>0.228214</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIOt6RWbCDOY",
        "colab_type": "code",
        "outputId": "f489dce8-d35a-40da-f713-4ff34e3be678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 1e-3, moms=(0.8, 0.7))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.458423</td>\n",
              "      <td>4.066679</td>\n",
              "      <td>0.294152</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoAW3DH_CKlh",
        "colab_type": "code",
        "outputId": "afca9000-7329-4e9f-e286-da4bdfeb360e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learn.predict(\"This is a review about\", n_words=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a review about barney gross gross explain : actually being into a non'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcJWXMA8CQ-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM94ghu8CULj",
        "colab_type": "code",
        "outputId": "f9e0ab2e-7988-40aa-b1b0-1d0cdbee980c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
        "learn.load_encoder('ft_enc')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (3389 items)\n",
              "x: TextList\n",
              "xxbos @cameron_gray xxunk @globeandmail xxmaj xxunk - up for so many xxunk .,xxbos @cnni xxmaj xxunk has made xxunk # xxup xxunk # weapons for decades : https : / / t.co / xxunk … xxmaj similar to those used on # xxunk,xxbos @simbad_reb @vegasrebs it 's worked for us for the last 18yrs has n't it ?,xxbos @igottatravel @mtats xxmaj uber is covering the cost of all rides .,xxbos @englishemma nope . i respect them for making the rides free , i can also see how they wanted to get more drivers in\n",
              "y: CategoryList\n",
              "Support,Support,Support,Support,Support\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (848 items)\n",
              "x: TextList\n",
              "xxbos xxunk maybe tomorrow ?,xxbos xxunk @zellieimani got me all wrong the robbery suspect is wearing xxunk but michael is wearing xxunk xxunk few mins later,xxbos @nbcnews so much for xxmaj local and xxmaj xxunk xxmaj media xxunk to a xxup no xxmaj publish of the building . xxmaj brilliant idiots as usual xxup xxunk,xxbos @cherylfolland @amyminsky @globalnational xxmaj probably meant xxup pm , in the afternoon xxunk,xxbos @colvinius @martinrjay xxmaj it 's not a matter of criticism , it 's insulting and xxunk and offensive\n",
              "y: CategoryList\n",
              "Query,Support,Support,Support,Deny\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3440, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3440, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f717c1ceb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (3389 items)\n",
              "x: TextList\n",
              "xxbos @cameron_gray xxunk @globeandmail xxmaj xxunk - up for so many xxunk .,xxbos @cnni xxmaj xxunk has made xxunk # xxup xxunk # weapons for decades : https : / / t.co / xxunk … xxmaj similar to those used on # xxunk,xxbos @simbad_reb @vegasrebs it 's worked for us for the last 18yrs has n't it ?,xxbos @igottatravel @mtats xxmaj uber is covering the cost of all rides .,xxbos @englishemma nope . i respect them for making the rides free , i can also see how they wanted to get more drivers in\n",
              "y: CategoryList\n",
              "Support,Support,Support,Support,Support\n",
              "Path: .;\n",
              "\n",
              "Valid: LabelList (848 items)\n",
              "x: TextList\n",
              "xxbos xxunk maybe tomorrow ?,xxbos xxunk @zellieimani got me all wrong the robbery suspect is wearing xxunk but michael is wearing xxunk xxunk few mins later,xxbos @nbcnews so much for xxmaj local and xxmaj xxunk xxmaj media xxunk to a xxup no xxmaj publish of the building . xxmaj brilliant idiots as usual xxup xxunk,xxbos @cherylfolland @amyminsky @globalnational xxmaj probably meant xxup pm , in the afternoon xxunk,xxbos @colvinius @martinrjay xxmaj it 's not a matter of criticism , it 's insulting and xxunk and offensive\n",
              "y: CategoryList\n",
              "Query,Support,Support,Support,Deny\n",
              "Path: .;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3440, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3440, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f717c1ceb70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
              "  (0): Embedding(3440, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3440, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(3440, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3440, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.2, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjLqwu6WCa9E",
        "colab_type": "code",
        "outputId": "ce971ddc-3cbc-49b7-eac8-48ace585b85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "data_clas.show_batch()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos .@marrty96 xxup and xxup yet xxup its xxup not xxup on / xxup in xxup the xxup tweet / xxup headline . xxup as xxup usual . &amp; &amp; xxup dont xxup fucking xxup tell xxup me xxup to xxup relax . \\n  xxup this xxup is xxup the xxup same xxup network xxup that xxup reported xxup xxunk</td>\n",
              "      <td>Support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos “ xxup @afp : xxmaj police stand guard as hostages are held in a cafe in xxmaj sydney . xxmaj follow xxup afp 's xxup live xxup report : http : / / t.co / xxunk http : / / t.co / xxunk ”</td>\n",
              "      <td>Support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj looks like every xxmaj charlie xxmaj hebdo cartoonist has been killed : 1 . xxmaj charb - was on xxmaj al - xxmaj qaeda 's hit list ; 2 . xxmaj cabu , 3 . xxmaj wolinski , 4 . xxmaj tignous</td>\n",
              "      <td>Comment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxup sydney xxup hostage - xxup taker \\n  - xxmaj man xxmaj xxunk , xxunk \\n  - xxmaj originally from xxmaj iran \\n  - xxmaj self - styled sheikh \\n  - xxmaj accused of xxunk assaulting 7 women \\n  xxup developing ..</td>\n",
              "      <td>Comment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxbos xxmaj this is the soldier who died today at the # xxmaj ottawa xxmaj war xxmaj memorial . xxmaj his name is xxmaj cpl . xxmaj nathan xxmaj cirillo . # xxup rip # xxunk http : / / t.co / xxunk</td>\n",
              "      <td>Comment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHwGIccnCftf",
        "colab_type": "code",
        "outputId": "9ff74799-140f-45cc-f335-43a563a851ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.984152</td>\n",
              "      <td>0.920869</td>\n",
              "      <td>0.647406</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwQgPHarFD7c",
        "colab_type": "code",
        "outputId": "2316dee3-1144-4ad5-ba80-2bcb367c768a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(5e-3/2., 5e-3), moms=(0.8, 0.7))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.887027</td>\n",
              "      <td>0.878570</td>\n",
              "      <td>0.682783</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2oE8dVFJRs",
        "colab_type": "code",
        "outputId": "5b73ba08-6b1b-4b27-ed0d-d69ed4eeeb64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10, slice(2e-3/100, 2e-3), moms=(0.8, 0.7))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.815512</td>\n",
              "      <td>0.866792</td>\n",
              "      <td>0.695755</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.842021</td>\n",
              "      <td>0.886857</td>\n",
              "      <td>0.670991</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.813521</td>\n",
              "      <td>0.873211</td>\n",
              "      <td>0.694575</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.760300</td>\n",
              "      <td>0.897621</td>\n",
              "      <td>0.694575</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.692841</td>\n",
              "      <td>0.902339</td>\n",
              "      <td>0.689858</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.598519</td>\n",
              "      <td>0.957939</td>\n",
              "      <td>0.695755</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.504438</td>\n",
              "      <td>0.996185</td>\n",
              "      <td>0.682783</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.461969</td>\n",
              "      <td>1.047890</td>\n",
              "      <td>0.681604</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.397825</td>\n",
              "      <td>1.015314</td>\n",
              "      <td>0.682783</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.444757</td>\n",
              "      <td>1.024292</td>\n",
              "      <td>0.678066</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DFYiOTrFQvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = []\n",
        "for text in test['text']:\n",
        "    l.append(str(learn.predict(text)[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mstsNb5hIVEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8ZQADzI5F4",
        "colab_type": "code",
        "outputId": "800f99c4-23b5-403d-dae8-bd434d390fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(test['label'], l)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7117437722419929"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOyYNvOnR-w4",
        "colab_type": "code",
        "outputId": "67a0e3c0-9d66-4f39-c732-adbf7987f3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_score(test['label'], l, average='macro')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5199528493008301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFDRzZXrWjZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}